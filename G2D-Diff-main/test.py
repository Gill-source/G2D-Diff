import torch
import pandas as pd
import numpy as np
from src.g2d_diff_ce import Condition_Encoder 
from src.g2d_diff_diff import Diffusion 

# -----------------------------
# Device ì„¤ì •
# -----------------------------
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"âœ… Using device: {device}\n")

# -----------------------------
# ì²´í¬í¬ì¸íŠ¸ ë¡œë“œ
# -----------------------------
ckpt_path = "diffusion_models/auto_save_epoch_290.ckpt"
print(f"Loading checkpoint: {ckpt_path}")

# torch 1.x does not support the weights_only argument, so keep the classic load signature.
try:
    ckpt = torch.load(ckpt_path, map_location=device)
except Exception as e:
    print("âŒ Error loading checkpoint:", e)
    exit()

# -----------------------------
# Diffusion ëª¨ë¸ ì´ˆê¸°í™”
# -----------------------------
print("Load pretrained diffusion model ...")
model = Diffusion() 
if "diffusion_state_dict" in ckpt:
    model.load_state_dict(ckpt["diffusion_state_dict"])
    print("âœ… Diffusion model loaded successfully.\n")
else:
    print("âš ï¸ diffusion_state_dict not found in checkpoint â€” using untrained weights.\n")
model.to(device)
model.eval()

# -----------------------------
# Condition Encoder ì´ˆê¸°í™”
# -----------------------------
print("Load pretrained cond_encoder ...")

# ëª¨ë¸ ê°€ì¤‘ì¹˜ê°€ 720 ë…¸ë“œì´ë¯€ë¡œ, Condition_Encoderì˜ num_of_genesë„ 720ìœ¼ë¡œ ë§ì¶¥ë‹ˆë‹¤.
target_genes_param = 720 

cond_encoder = Condition_Encoder(
    num_of_genotypes=3,     
    num_of_dcls=5,          
    num_of_genes=target_genes_param,  # âœ… 720 ì„¤ì •
    gene_emb_size=128,
    device=device,
    neighbor_info=True
)

if "cond_state_dict" in ckpt:
    cond_encoder.load_state_dict(ckpt["cond_state_dict"])
    print("âœ… Condition_Encoder loaded successfully.\n")
else:
    print("âš ï¸ cond_state_dict not found in checkpoint â€” using randomly initialized encoder.\n")

# -----------------------------------------------------------
# ğŸ› ï¸ [ë°ì´í„° íŒ¨ë”© 1] ì¸ì ‘ í–‰ë ¬(Adj): 718 -> 720
# ì„¤ì •ê°’(720)ê³¼ ë§ì¶”ê¸° ìœ„í•´ ì›ë³¸ ë°ì´í„°ë¥¼ 720ìœ¼ë¡œ ëŠ˜ë¦½ë‹ˆë‹¤.
# -----------------------------------------------------------
current_adj = cond_encoder.gene_adj
required_adj_size = target_genes_param # 720

if current_adj.shape[0] != required_adj_size:
    print(f"ğŸ”§ Padding adjacency matrix: {current_adj.shape} -> ({required_adj_size}, {required_adj_size})")
    
    new_adj = torch.zeros((required_adj_size, required_adj_size), device=device, dtype=current_adj.dtype)
    
    # ì›ë³¸(718x718)ì„ ë³µì‚¬
    orig_h, orig_w = current_adj.shape
    new_adj[:orig_h, :orig_w] = current_adj
    
    # êµì²´
    cond_encoder.gene_adj = new_adj

cond_encoder.to(device)
cond_encoder.eval()
print("âœ… ConditionEncoder ready.\n")

# -----------------------------
# í…ŒìŠ¤íŠ¸ìš© ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
# -----------------------------
meta = pd.read_csv("./data/drug_response_data/DC_drug_response.csv")
cell_names = meta["ccle_name"].values
cell2mut = pd.read_csv("./data/drug_response_data/original_cell2mut.csv")

# í…ŒìŠ¤íŠ¸í•  ì…€ ì„ íƒ
cell_index = 33 
if cell_index >= len(cell2mut):
    raise IndexError(f"âŒ cell_index {cell_index} out of range (max {len(cell2mut)-1})")

cell_name = cell_names[cell_index]
print(f"Using cell: {cell_name}, index = {cell_index}")

# -----------------------------
# mutation ë²¡í„° ì²˜ë¦¬
# -----------------------------
mut_vec = cell2mut.iloc[cell_index].values
mut_vec = pd.to_numeric(mut_vec, errors="coerce")

if mut_vec is None or np.isnan(mut_vec).all():
    raise ValueError("âŒ Mutation vector is empty or invalid.")

mut_vec = np.nan_to_num(mut_vec, nan=0.0)
mut_vec = mut_vec.astype(float) 
mut_vec = torch.FloatTensor(mut_vec).unsqueeze(0).to(device) # (1, 718)

# -----------------------------------------------------------
# ğŸ› ï¸ [ë°ì´í„° íŒ¨ë”© 2] ì…ë ¥ ë²¡í„°(Mut): 718 -> 720
# ëª¨ë¸ì˜ ìµœì¢… ì…ë ¥ì¸µ(ê°€ì¤‘ì¹˜)ì€ 720ì„ ê¸°ëŒ€í•˜ë¯€ë¡œ 720ê¹Œì§€ ì±„ì›ë‹ˆë‹¤.
# -----------------------------------------------------------
required_input_size = 720 # ê°€ì¤‘ì¹˜ í¬ê¸°

if mut_vec.shape[1] != required_input_size:
    print(f"ğŸ”§ Padding mutation vector: {mut_vec.shape} -> (1, {required_input_size})")
    padded_mut = torch.zeros((1, required_input_size), device=device)
    
    # ì›ë³¸(718) ë³µì‚¬
    padded_mut[:, :mut_vec.shape[1]] = mut_vec
    mut_vec = padded_mut

print("âœ… Mutation vector loaded and converted successfully.\n")

# -----------------------------
# ì¸í¼ëŸ°ìŠ¤ ì‹œë®¬ë ˆì´ì…˜
# -----------------------------
with torch.no_grad():
    dummy_input = {
        "genotype": {"MUT": mut_vec, "CNA": mut_vec, "CND": mut_vec},
        "class": torch.randint(0, 5, (1,)).to(device), 
    }
    
    _, cond_out, _, _ = cond_encoder(dummy_input)
    cond_out = cond_out.float()  # ensure float32 for diffusion model
    print("âœ… Condition encoding complete.")

    # Diffusion.forward expects a batch dict with keys 'drug', 'class', 'genotype'.
    # ë‚´ë¶€ Diffusionì˜ condition_encoderëŠ” í•™ìŠµëœ 718 ìœ ì „ì ì„¤ì •ì„ ì‚¬ìš©í•˜ë¯€ë¡œ
    # genotype ì…ë ¥ì„ 718ë¡œ ì˜ë¼ì„œ ì „ë‹¬í•©ë‹ˆë‹¤.
    genotype_for_diffusion = {
        k: v[:, :718].contiguous() for k, v in dummy_input["genotype"].items()
    }
    batch_for_diffusion = {
        "drug": cond_out,                 # use conditioned embedding as drug input
        "class": dummy_input["class"],
        "genotype": genotype_for_diffusion,
    }

    print(f"cond_out dtype: {cond_out.dtype}, device: {cond_out.device}")
    print(f"drug dtype: {batch_for_diffusion['drug'].dtype}")
    for k,v in batch_for_diffusion['genotype'].items():
        print(f"genotype {k} dtype: {v.dtype}, shape: {v.shape}")

    pred = model(batch_for_diffusion)
    print("âœ… Diffusion output shape:", pred.shape)

print("\nğŸ¯ Test completed successfully.")
